{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, EDA, and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import k_means, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In the Collected Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In the S&P 500 Financial Statement Data (This is a dictionary saved as a csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./data/spx_df.csv' does not exist: b'./data/spx_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1abbb6b54eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspx_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/spx_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./data/spx_df.csv' does not exist: b'./data/spx_df.csv'"
     ]
    }
   ],
   "source": [
    "spx_df = pd.read_csv('./data/spx_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In the S&P 500 Company Sector Data as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx = pd.read_csv('./data/constituents_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In the S&P 500 Financial Stats as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_stats = pd.read_csv('./data/spx_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already done a lot of the cleaning during the scrape. Therefore, our cleaning work is easier here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the S&P 500 Stats DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start simple and start cleaning spx_stats since it is already a standarized format. We will drop some unneccessary columns and drop the columns with more than 50 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Unammed: 0 column.\n",
    "spx_stats.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the symbol column, it is redundent.\n",
    "spx_stats.drop(columns='Symbol', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_stats = spx_stats.loc[:, spx_stats.isnull().sum() < 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Financial Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaning here is a bit more complex. As the accounting system allows certain flexibility, companies report slightly different line items in their financial statements. It would be a mess to directly concat the DataFrames. \n",
    "\n",
    "Instead, we try to take a look under the hood and only grab the key columns we need for our purpose. We need to make sure the columns that we need for modeling are common among the companies. To do this, we created another function to quickly test if a particular column is widely reported by companies tracked in S&P 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a List of Useful Columns to Include for Our Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_cols = [col for col in spx_df.columns if col.startswith('(BS)')]\n",
    "bs_cols.insert(0, 'Ticker')\n",
    "is_cols = [col for col in spx_df.columns if col.startswith('(IS)')]\n",
    "is_cols.insert(0, 'Ticker')\n",
    "cf_cols = [col for col in spx_df.columns if col.startswith('(CF)')]\n",
    "cf_cols.insert(0, 'Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_list = ['Date',\n",
    "               'Ticker',\n",
    "               '(BS) Cash And Cash Equivalents', \n",
    "               '(BS) Short Term Investments',\n",
    "               '(BS) Total Cash',\n",
    "               '(BS) Gross property, plant and equipment',\n",
    "               '(BS) Accumulated Depreciation',\n",
    "               '(BS) Net property, plant and equipment',\n",
    "               '(BS) Total Assets',\n",
    "               '(BS) Accounts Payable',\n",
    "               '(BS) Taxes payable',\n",
    "               '(BS) Accrued liabilities',\n",
    "               '(BS) Deferred revenues',\n",
    "               '(BS) Other Current Liabilities',\n",
    "               '(BS) Total Liabilities',\n",
    "               '(BS) Retained Earnings',\n",
    "               '(BS) Total liabilities and stockholders\\' equity',\n",
    "               '(IS) Total Revenue',\n",
    "               '(IS) Cost of Revenue',\n",
    "               '(IS) Gross Profit',\n",
    "               '(IS) Total Operating Expenses',\n",
    "               '(IS) Operating Income or Loss',\n",
    "               '(IS) Interest Expense',\n",
    "               '(IS) Income Before Tax',\n",
    "               '(IS) Income Tax Expense',\n",
    "               '(IS) Net Income',\n",
    "               '(IS) Net Income available to common shareholders',\n",
    "               '(IS) EBITDA',\n",
    "               '(CF) Depreciation & amortization',\n",
    "               '(CF) Change in working capital',\n",
    "               '(CF) Capital Expenditure',\n",
    "               '(CF) Free Cash Flow',\n",
    "               '(CF) Dividends Paid',\n",
    "               '(CF) Net cash provided by operating activites',\n",
    "               '(CF) Net cash used privided by (used for) financing activities',\n",
    "               '(CF) Net cash used for investing activites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin = spx_df[useful_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the `spx_fin` DataFrame: Make Sure We Have the Target Variable for All Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "spx_fin.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total cash can be inferred from Cash and Cash Equivalents. Therefore, we want to make sure we have a total cash available for each observation. There are many reasons why total cash or categorized cash numbers are missing. This could due to a young company who went IPO and filed for a incomplete statement during their first year. This is totally normal. For our purposes, we will drop such rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the missing values.\n",
    "spx_fin.loc[spx_fin['(BS) Cash And Cash Equivalents'].isnull().astype(int) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that there are some tickers missing. Drop these rows as this could very likely be a scraping error.\n",
    "spx_fin = spx_fin.loc[spx_fin['Ticker'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, FTV's 2015 filing is incomplete as they went public that year. Drop this row.\n",
    "spx_fin = spx_fin.drop(1050, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MU and CAT reported Total Cash, which is eventually what we want. So this is OK.\n",
    "spx_fin.loc[spx_fin['(BS) Cash And Cash Equivalents'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to make sure there's no null values in our target variable: (BS) Total Cash. We know that total cash:\n",
    "\n",
    "- Total Cash = Cash & Cash Equivalent + Short-term Investments\n",
    "<br>\n",
    "\n",
    "First, fill the nas for short-term investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin['(BS) Short Term Investments'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin['(BS) Total Cash'].fillna(spx_fin['(BS) Cash And Cash Equivalents'] + spx_fin['(BS) Short Term Investments'],\n",
    "                                  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin.loc[spx_fin['(BS) Total Cash'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the cash and cash equivalent and short-term investment columns for simplicity purposes.\n",
    "spx_fin.drop(columns=['(BS) Cash And Cash Equivalents', '(BS) Short Term Investments'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the `spx_fin` DataFrame: Dealing w/ Other Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PPE items, we can simply fillna with 0. Some companies don't have PPE.\n",
    "spx_fin['(BS) Gross property, plant and equipment'] = spx_fin['(BS) Gross property, plant and equipment'].fillna(0)\n",
    "spx_fin['(BS) Accumulated Depreciation'] = spx_fin['(BS) Accumulated Depreciation'].fillna(0)\n",
    "\n",
    "# We can drop Net PPE since we have the other two broken down conponents.\n",
    "spx_fin.drop(columns='(BS) Net property, plant and equipment', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For short-term liability items, since some companies don't have these liabilities, it is also safe to fillna with 0.\n",
    "spx_fin['(BS) Accounts Payable'] = spx_fin['(BS) Accounts Payable'].fillna(0)\n",
    "spx_fin['(BS) Taxes payable'] = spx_fin['(BS) Taxes payable'].fillna(0)\n",
    "spx_fin['(BS) Accrued liabilities'] = spx_fin['(BS) Accrued liabilities'].fillna(0)\n",
    "spx_fin['(BS) Deferred revenues'] = spx_fin['(BS) Deferred revenues'].fillna(0)\n",
    "spx_fin['(BS) Other Current Liabilities'] = spx_fin['(BS) Other Current Liabilities'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at retained earnings, and why some of the values are missing.\n",
    "# For the missing values, we can infer from total shareholder's equity.\n",
    "# The average retained earning over shareholder's equity over the S&P 500 companies is around 26%.\n",
    "mean_re_perc = np.mean(spx_fin['(BS) Retained Earnings'] / spx_fin['(BS) Total liabilities and stockholders\\' equity'])\n",
    "spx_fin['(BS) Retained Earnings'] = spx_fin['(BS) Retained Earnings'].fillna(spx_fin['(BS) Total liabilities and stockholders\\' equity']*mean_re_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenue is a key part of our project and we are seeing 12 rows with hidden value. After some digging on Yahoo Finance, we found that the following data is incomplete and hidden from the page. We should have other ways to collect these data, using the official 10K or 10Q. But given the time contrainst, we will for now drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin[spx_fin['(IS) Total Revenue'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin = spx_fin[spx_fin['(IS) Total Revenue'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be some significant inferrance going on in the next section. In order to get the real values as accurate as possible, we need to fill the sector data for each company as companies in a specific sector behave in a similar fashion.\n",
    "\n",
    "But again, with time constratins. We will use this method in future editions and trust the law of large numbers. Instead of going sector by sector, we are just going to use the average of the S&P 500 companies to deduce these missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin = spx_fin.merge(spx, how='left', left_on='Ticker', right_on='Symbol').drop(columns='Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fillna for cost of revenue by the mean.\n",
    "mean_gr_perc = np.mean(spx_fin['(IS) Cost of Revenue'] / spx_fin['(IS) Total Revenue'])\n",
    "spx_fin['(IS) Cost of Revenue'] = spx_fin['(IS) Cost of Revenue'].fillna(spx_fin['(IS) Total Revenue']*mean_gr_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we are done with the cost of revenue, we can fill the gross revenue as it is a simple deduction.\n",
    "spx_fin['(IS) Gross Profit'] = spx_fin['(IS) Gross Profit'].fillna(spx_fin['(IS) Total Revenue']-spx_fin['(IS) Cost of Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same way as above, we fillnas for the operating expenses and operating profits.\n",
    "mean_oex_perc = np.mean(spx_fin['(IS) Total Operating Expenses'] / spx_fin['(IS) Total Revenue'])\n",
    "spx_fin['(IS) Total Operating Expenses'] = spx_fin['(IS) Total Operating Expenses'].fillna(spx_fin['(IS) Total Revenue']*mean_oex_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the operating income or loss based on this.\n",
    "spx_fin['(IS) Operating Income or Loss'] = spx_fin['(IS) Operating Income or Loss'].fillna(spx_fin['(IS) Gross Profit']-spx_fin['(IS) Total Operating Expenses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interest expense and income tax expenses, it's reasonable that a few companies don't have debt or experiencing loss.\n",
    "spx_fin['(IS) Interest Expense'] = spx_fin['(IS) Interest Expense'].fillna(0)\n",
    "spx_fin['(IS) Income Tax Expense'] = spx_fin['(IS) Income Tax Expense'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will return to EBITA last, let's first deal with cash flows.\n",
    "# There are 2 rows without any cash flows, smoke them out and drop.\n",
    "spx_fin = spx_fin[spx_fin['(CF) Net cash provided by operating activites'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some companies don't pay dividends. Fill with 0s.\n",
    "spx_fin['(CF) Dividends Paid'] = spx_fin['(CF) Dividends Paid'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depreciation and amortization can be thought as a function of operating cash flow.\n",
    "# Again, there are better ways to do this based on sectors. But for now, I'll settle with the mean of the mass.\n",
    "mean_da_perc = np.mean(spx_fin['(CF) Depreciation & amortization'] / spx_fin['(CF) Net cash provided by operating activites']) \n",
    "spx_fin['(CF) Depreciation & amortization'] = spx_fin['(CF) Depreciation & amortization'].fillna(spx_fin['(CF) Net cash provided by operating activites']*mean_da_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same way with change in working capital. Follow the approach of the above cell.\n",
    "mean_wc_perc = np.mean(spx_fin['(CF) Change in working capital'] / spx_fin['(CF) Net cash provided by operating activites']) \n",
    "spx_fin['(CF) Change in working capital'] = spx_fin['(CF) Change in working capital'].fillna(spx_fin['(CF) Net cash provided by operating activites']*mean_wc_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing capex will be deduced bassed on the Revenue.\n",
    "mean_wc_perc = np.mean(spx_fin['(CF) Capital Expenditure'] / spx_fin['(IS) Total Revenue']) \n",
    "spx_fin['(CF) Capital Expenditure'] = spx_fin['(CF) Capital Expenditure'].fillna(spx_fin['(IS) Total Revenue']*mean_wc_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's deal with EBITDA.\n",
    "spx_fin['(IS) EBITDA'] = spx_fin['(IS) EBITDA'].fillna(spx_fin['(IS) Net Income']+spx_fin['(IS) Interest Expense']+spx_fin['(IS) Income Tax Expense']+spx_fin['(CF) Depreciation & amortization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, free cash flow.\n",
    "spx_fin['(CF) Free Cash Flow'] = spx_fin['(CF) Free Cash Flow'].fillna(spx_fin['(IS) Net Income']+spx_fin['(IS) Interest Expense']-spx_fin['(IS) Interest Expense']*0.21+spx_fin['(CF) Change in working capital']-spx_fin['(CF) Capital Expenditure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We are all good to go.\n",
    "spx_fin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: Financial Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Between Cash Balance and Rest of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,12))\n",
    "sns.heatmap(spx_fin.corr()[['(BS) Total Cash']][1:].sort_values('(BS) Total Cash', ascending=False),\n",
    "            annot=True,\n",
    "            cmap='RdBu',\n",
    "            vmax=1,\n",
    "            vmin=-1,\n",
    "            annot_kws={'size' : 20})\n",
    "plt.title('Correlation Between Cash Balance and Other Items on the Financial Statement',\n",
    "          fontsize=20,\n",
    "          pad=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Cash Balance by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "(spx_fin.groupby('Sector').mean().sort_values('(BS) Total Cash')[['(BS) Total Cash']]/1000).plot.barh(figsize=(10,8))\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Mean Cash Balance By Industry ($M)', fontsize=20, pad=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash/Asset Ration By Industry (Adjusted to Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to adjust for scale of a company\n",
    "spx_fin['Cash/Total Asset'] = spx_fin['(BS) Total Cash'] / spx_fin['(BS) Total Assets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "(spx_fin.groupby('Sector').mean().sort_values('Cash/Total Asset')[['Cash/Total Asset']]).plot.barh(figsize=(10,8), color='maroon')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Cash/Asset Ratio By Industry', fontsize=20, pad=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Most Recent Financial Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple years of financial statements in our hand. But we are more interested in the most recent year with the exception of growth rate. \n",
    "\n",
    "**NOTE:** With time contrainst, we haven't been able to calculate growth rate but used some proxy provided by the statistics of Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent statement for each company.\n",
    "spx_fin_recent = spx_fin.sort_index(axis=0, ascending=True).drop_duplicates(['Ticker'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_fin_recent['(BS) Total Cash'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Look at Our y Variable, Much Better with Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(spx_fin_recent['(BS) Total Cash'])\n",
    "plt.title('Total Cash', fontsize=20, pad=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(np.log(spx_fin_recent['(BS) Total Cash']+0.0001))\n",
    "plt.title('Log (Total Cash)', fontsize=20, pad=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(spx_fin_recent['Cash/Total Asset'])\n",
    "plt.title('Cash/Total Asset Ratio', fontsize=20, pad=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(np.log(spx_fin_recent['Cash/Total Asset']+0.00001))\n",
    "plt.title('Log (Cash/Total Asset Ratio)', fontsize=20, pad=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish a Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x=range(len(spx_fin_recent['Cash/Total Asset'])),\n",
    "                y=spx_fin_recent['Cash/Total Asset'],\n",
    "                alpha=0.5)\n",
    "plt.hlines(y=np.mean(spx_fin_recent['Cash/Total Asset']),\n",
    "           xmin=0,\n",
    "           xmax=473,\n",
    "           color='r',\n",
    "           linestyles='dashed',\n",
    "           label='S&P 500 Mean Cash/Asset Ratio')\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('Cash / Asset Ratio', fontsize=15)\n",
    "plt.legend()\n",
    "plt.title('Cash / Asset Ratio v.s. the Mean',\n",
    "          fontsize=20,\n",
    "          pad=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_useful_list = ['Ticker',\n",
    "                     'Name',\n",
    "                     'Sector',\n",
    "                     '% Held by Insiders',\n",
    "                     '% Held by Institutions',\n",
    "                     'Beta (3Y Monthly)',\n",
    "                     'Current Ratio (mrq)',\n",
    "                     'Diluted EPS (ttm)',\n",
    "                     'EBITDA',\n",
    "                     'Enterprise Value',\n",
    "                     'Enterprise Value/EBITDA',\n",
    "                     'Enterprise Value/Revenue',\n",
    "                     'Forward P/E',\n",
    "                     'Gross Profit (ttm)',\n",
    "                     'Market Cap (intraday)',\n",
    "                     'PEG Ratio (5 yr expected)',\n",
    "                     'Payout Ratio',\n",
    "                     'Price/Book (mrq)',\n",
    "                     'Price/Sales (ttm)',\n",
    "                     'Quarterly Revenue Growth (yoy)',\n",
    "                     'Return on Assets (ttm)',\n",
    "                     'Return on Equity (ttm)',\n",
    "                     'S&P500 52-Week Change',\n",
    "                     'Short Ratio (Nov 15, 2019)',\n",
    "                     'Total Cash (mrq)',\n",
    "                     'Total Debt (mrq)',\n",
    "                     'Total Debt/Equity (mrq)',\n",
    "                     'Trailing P/E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_stats_useful = spx_stats[stats_useful_list]\n",
    "df_final = spx_stats_useful.merge(spx_fin_recent.drop(columns=['Name','Sector']), how='left', on='Ticker')\n",
    "df_final = pd.get_dummies(df_final, columns=['Sector'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['Beta (3Y Monthly)',\n",
    " 'Current Ratio (mrq)',\n",
    " 'PEG Ratio (5 yr expected)',\n",
    " 'Payout Ratio',\n",
    " 'Quarterly Revenue Growth (yoy)',\n",
    " 'Return on Assets (ttm)',\n",
    " 'Return on Equity (ttm)',\n",
    " 'Total Debt (mrq)',\n",
    " 'Total Debt/Equity (mrq)',\n",
    " '(BS) Gross property, plant and equipment',\n",
    " '(BS) Accumulated Depreciation',\n",
    " '(BS) Total Assets',\n",
    " '(BS) Accounts Payable',\n",
    " '(BS) Taxes payable',\n",
    " '(BS) Accrued liabilities',\n",
    " '(BS) Deferred revenues',\n",
    " '(BS) Other Current Liabilities',\n",
    " '(BS) Total Liabilities',\n",
    " '(BS) Retained Earnings',\n",
    " \"(BS) Total liabilities and stockholders' equity\",\n",
    " '(IS) Total Revenue',\n",
    " '(IS) Cost of Revenue',\n",
    " '(IS) Gross Profit',\n",
    " '(IS) Total Operating Expenses',\n",
    " '(IS) Operating Income or Loss',\n",
    " '(IS) Interest Expense',\n",
    " '(IS) Income Before Tax',\n",
    " '(IS) Income Tax Expense',\n",
    " '(IS) Net Income',\n",
    " '(IS) Net Income available to common shareholders',\n",
    " '(IS) EBITDA',\n",
    " '(CF) Depreciation & amortization',\n",
    " '(CF) Change in working capital',\n",
    " '(CF) Capital Expenditure',\n",
    " '(CF) Free Cash Flow',\n",
    " '(CF) Dividends Paid',\n",
    " '(CF) Net cash provided by operating activites',\n",
    " '(CF) Net cash used privided by (used for) financing activities',\n",
    " '(CF) Net cash used for investing activites',\n",
    " 'Sector_Consumer Staples',\n",
    " 'Sector_Energy',\n",
    " 'Sector_Financials',\n",
    " 'Sector_Health Care',\n",
    " 'Sector_Industrials',\n",
    " 'Sector_Information Technology',\n",
    " 'Sector_Materials',\n",
    " 'Sector_Real Estate',\n",
    " 'Sector_Telecommunication Services',\n",
    " 'Sector_Utilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(df_final['(BS) Total Cash']+0.000001)\n",
    "X = df_final[X_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are building a linear regression to project the \"fair cash balance\" of a company with specific characteristics: growth, scale, retention rate, etc. \n",
    "\n",
    "There are many ways we could improve this model, including but not limited to the following:\n",
    "\n",
    "- Get more historical data to better understand the company's grwoth tractory instead of just relying on current day statistics.\n",
    "- Deep dive into sectors and industries within those sectors to understand how companies with different characteristcs behave.\n",
    "- Understanding macro market environment, such as interest rate, inflation, unemployment and overall GDP growth.\n",
    "- Puting these company on a global scale, looking not only how companies perform in the US but how they behave in Europe, Asia Pacifics, South America and other global and regional markets.\n",
    "- Infer better data points that are more correlated with our target, such as weight average cost of capital, return on capital, research and operations, etc.\n",
    "\n",
    "Right now, we have a MVP, which is a fundamental project we can built upon. From this project, we are just scratching the surface of the topic but we have the tools to make drive much more insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "lm = sm.OLS(y,X).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fair = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Fair Cash Balance'] = np.exp(y_fair)\n",
    "df_final['Cash Diff'] = df_final['(BS) Total Cash'] - df_final['Fair Cash Balance']\n",
    "df_final['Fair Cash Balance'] = df_final['Fair Cash Balance']\n",
    "df_final['Cash Diff'] = df_final['Cash Diff']\n",
    "df_cash = df_final[['Ticker', '(BS) Total Cash', 'Fair Cash Balance', 'Cash Diff', '(BS) Total Assets', 'Quarterly Revenue Growth (yoy)', 'S&P500 52-Week Change']]\n",
    "df_cash = df_cash.merge(spx, how='left', left_on='Ticker', right_on='Symbol').drop(columns='Symbol')\n",
    "df_cash = df_cash[['Ticker', 'Name', 'Sector', '(BS) Total Cash', 'Fair Cash Balance', 'Cash Diff', '(BS) Total Assets', 'Quarterly Revenue Growth (yoy)', 'S&P500 52-Week Change']]\n",
    "df_cash = df_cash.round(2)\n",
    "df_cash['Excessive Cash / Total Asset'] = df_cash['Cash Diff'] / df_cash['(BS) Total Assets']\n",
    "df_cash['*Estimated Value Loss by Public Investors'] = df_cash['Cash Diff'] * df_cash['S&P500 52-Week Change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companies with Most Excessive Cash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Companies with the most excess cash. There are many financial services firms in this list. This is not surprising as banks are required to carry more cash on their balance sheet to provide liquidity to the financial system.\n",
    "\n",
    "Also, banking regulation is a lot more complex than other industries due to the fallout of the 2018 financial crisis. Banks are de-levering as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cash.sort_values('Cash Diff', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companies with Most Excessive Cash Outside of Financial Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash.loc[df_cash['Sector'] != 'Financials'].sort_values('Cash Diff', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companies with Insufficient Cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash.loc[df_cash['Sector'] != 'Financials'].sort_values('Cash Diff', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companies with The Larget Excessive Cash / Total Asset Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash.sort_values('Excessive Cash / Total Asset', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash.loc[df_cash['Sector'] != 'Financials'].sort_values('Excessive Cash / Total Asset', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just out of curiousity, if the companies could be clustered based on their characteristics. By definition, companies of the same sector should display similar characteristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_num = df_final._get_numeric_data().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "db_X_sc = ss.fit_transform(df_final_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=3, min_samples=10)\n",
    "dbscan.fit(db_X_sc)\n",
    "print(set(dbscan.labels_))\n",
    "print(silhouette_score(db_X_sc, dbscan.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['cluster'] = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final.groupby('cluster').mean().T.loc[:, :].tail(13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
